#!/usr/bin/bash

: ${DIR=lists}

set -e

## https://www.proxydocker.com/

# Responce JSON contains types like 17, 127 for same HTTP proxies... And I have not found dictionary. Furthermore, there is looks like applied limit on 3 pages, so by each type it will downloading more.
# So, requesting by types


token=$(curl -sS --cookie-jar "${DIR}"/.proxydocker.com.cookies https://www.proxydocker.com/ | sed -rn 's/.+?name="_token".+content\s*=\s*"(.+)".+/\1/p') # "

for type in http https socks socks4 socks5; do
	echo "Process type[$type]"
	for page in {01..10}; do
		echo "	Downloading page [$page]"
		OUT=$(curl --connect-timeout 7 --max-time 20 -sS -X POST --data "token=${token}&country=all&city=all&state=all&port=all&type=all&anonymity=all&need=all&page=${page}" \
			--cookie "${DIR}"/.proxydocker.com.cookies \
				https://www.proxydocker.com/en/api/proxylist/ \
					| tee "${DIR}/.proxydocker.com.${type}.page${page}.${type}.json.orig")
		length=$( echo "$OUT" | jq '.proxies | length' )
		[[ 0 == $length ]] && echo "	Page [$page] empty. Exiting" && break
		echo "$OUT" | jq -r ".proxies[] | \"${type}://\(.ip):\(.port)\"" >> "${DIR}/proxydocker.com.all.txt"
	done
done
